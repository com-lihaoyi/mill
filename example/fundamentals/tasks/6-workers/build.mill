// Mill workers defined using `Task.Worker` are long-lived in-memory objects that
// can persistent across multiple evaluations. These are similar to persistent
// tasks in that they let you cache things, but the fact that they let you
// cache the worker object in-memory allows for greater performance and
// flexibility: you are no longer limited to caching only serializable data
// and paying the cost of serializing it to disk every evaluation.
//
// This example uses a Worker to provide simple two-level cache: in-memory caching
// for compressed files, in addition to caching them on disk. This means that if the
// Mill process is persistent (e.g. with `--watch`/`-w`) the cache lookups are instant,
// but even if the Mill process is restarted it can load the cache values from disk
// without having to recompute them:

package build
import mill._, scalalib._
import java.util.Arrays
import java.io.ByteArrayOutputStream
import java.util.zip.GZIPOutputStream

def data = Task.Source(millSourcePath / "data")

def compressWorker = Task.Worker { new CompressWorker(Task.dest) }

def compressedData = Task {
  println("Evaluating compressedData")
  for (p <- os.list(data().path)) {
    os.write(
      Task.dest / s"${p.last}.gz",
      compressWorker().compress(p.last, os.read.bytes(p))
    )
  }
  os.list(Task.dest).map(PathRef(_))
}

class CompressWorker(dest: os.Path) {
  val cache = collection.mutable.Map.empty[Int, Array[Byte]]
  def compress(name: String, bytes: Array[Byte]): Array[Byte] = {
    val hash = Arrays.hashCode(bytes)
    if (!synchronized(cache.contains(hash))) {
      val cachedPath = dest / hash.toHexString
      if (!os.exists(cachedPath)) {
        println("Compressing: " + name)
        val compressed = compressBytes(bytes)
        synchronized {
          cache(hash) = compressed
          os.write(cachedPath, cache(hash))
        }
      } else {
        println("Cached from disk: " + name)
        synchronized {
          cache(hash) = os.read.bytes(cachedPath)
        }
      }
    } else {
      println("Cached from memory: " + name)
    }
    synchronized { cache(hash) }
  }
}

def compressBytes(input: Array[Byte]) = {
  val bos = new ByteArrayOutputStream(input.length)
  val gzip = new GZIPOutputStream(bos)
  gzip.write(input)
  gzip.close()
  bos.toByteArray
}

// Common things to put in workers include:
//
// 1. References to third-party daemon processes, e.g. Webpack or wkhtmltopdf,
//    which perform their own in-memory caching
//
// 2. Classloaders containing plugin code, to avoid classpath conflicts while
//    also avoiding classloading cost every time the code is executed
//
// NOTE: The _initialization_ of a `Task.Worker`'s value is single threaded,
// but _usage_ of the worker's value may be done concurrently. The user of
// `Task.Worker` is responsible for ensuring it's value is safe to use in a
// multi-threaded environment via techniques like locks, atomics, or concurrent data
// structures. The example above uses `synchronized{}` around all access to the
// shared `cache` state to allow the slow `compressBytes` operation to run in
// parallel while the fast mutation of the `cache` is single-threaded.
//
// Workers live as long as the Mill process. By default, consecutive `mill`
// commands in the same folder will re-use the same Mill process and workers,
// unless `--no-server` is passed which will terminate the Mill process and
// workers after every command. Commands run repeatedly using `--watch` will
// also preserve the workers between them.
//
// Workers can also make use of their `Task.dest` folder as a cache that persist
// when the worker shuts down, as a second layer of caching. The example usage
// below demonstrates how using the `--no-server` flag will make the worker
// read from its disk cache, where it would have normally read from its
// in-memory cache

/** Usage

> ./mill show compressedData
Evaluating compressedData
Compressing: hello.txt
Compressing: world.txt
[
  ".../hello.txt.gz",
  "...world.txt.gz"
]

> ./mill compressedData # when no input changes, compressedData does not evaluate at all

> sed -i.bak 's/Hello/HELLO/g' data/hello.txt

> ./mill compressedData # not --no-server, we read the data from memory
Compressing: hello.txt
Cached from memory: world.txt

> ./mill compressedData # --no-server, we read the data from disk
Compressing: hello.txt
Cached from disk: world.txt

*/

// Mill uses workers to manage long-lived instances of the
// https://github.com/sbt/zinc[Zinc Incremental Scala Compiler] and the
// https://github.com/scala-js/scala-js[Scala.js Optimizer].
// This lets us keep them in-memory with warm caches and fast incremental execution.
//
// Like any other task, you can use `./mill clean` to wipe out any cached in-memory or
// on-disk state belonging to workers. This may be necessary if your worker implementation
// has bugs that cause the worker disk or in-memory data structures to get into a bad state.
//
// === `Autoclosable` Workers
//
// As <<Workers>> may also hold limited resources, it may be necessary to free up these resources once a worker is no longer needed.
// This is especially the case, when your worker tasks depends on other tasks and these tasks change, as Mill will then also create a new worker instance.
//
// To implement resource cleanup, your worker can implement `java.lang.AutoCloseable`.
// Once the worker is no longer needed, Mill will call the `close()` method on it before any newer version of this worker is created.

import mill._
import java.lang.AutoCloseable

class MyWorker() extends AutoCloseable {
  // ...
  override def close() = { /* cleanup and free resources */ }
}

def myWorker = Task.Worker { new MyWorker() }

// === `CachedFactory` Workers
//
// One very common use case for workers is managing long-lived mutable state. The issue
// with long-lived mutable state is that in the presence of parallelism (the default in
// Mill), managing such state can be tricky:
//
// * If you allow unrestricted access to the mutable state across multiple threads,
//   you are subject to race conditions and non-deterministic bugs
//
// * If you just synchronize/lock all access to the mutable state, you lose all benefits
//   for parallelism
//
// * If you re-generate the mutable state each time for each thread, you lose the benefits
//   of it being long lived
//
// The solution to these issues is to maintain an in-memory cache, with proper locking,
// eviction, and invalidation. Doing so is tedious and error prone, and so Mill provides
// the `CachedFactory` helper to make it easier. The example below re-implements the a simplified
// version of `CompressWorker` we saw earlier, but using `CacheFactory` to cache, reset, and
// re-use the `ByteArrayOutputStream` btween calls to `compressWorker2().compress`:
//
import mill._
import java.lang.AutoCloseable
import mill.api.CachedFactory
import java.io.ByteArrayOutputStream

def cachedCompressWorker = Task.Worker { new CachedCompressWorker(Task.dest) }
class CachedCompressWorker(dest: os.Path) extends CachedFactory[Unit, ByteArrayOutputStream] {
  def setup(key: Unit): ByteArrayOutputStream = {
    println("setup ByteArrayOutputStream")
    new ByteArrayOutputStream()
  }

  def teardown(key: Unit, value: ByteArrayOutputStream): Unit = {
    println("teardown ByteArrayOutputStream")
    value.reset()
  }

  def maxCacheSize = 2

  val cache = collection.mutable.Map.empty[Int, Array[Byte]]
  def compress(name: String, bytes: Array[Byte]): Array[Byte] = {
    val hash = Arrays.hashCode(bytes)
    if (!synchronized(cache.contains(hash))) {
      println("Compressing: " + name)
      val compressed = withValue(()) { bos => compressBytes2(bos, bytes) }
      synchronized { cache(hash) = compressed }
    } else {
      println("Cached from memory: " + name)
    }
    synchronized { cache(hash) }
  }
}

def compressBytes2(bos: ByteArrayOutputStream, input: Array[Byte]) = {
  bos.reset()
  Thread.sleep(1000) // Simulate a slow operation
  val gzip = new GZIPOutputStream(bos)
  gzip.write(input)
  gzip.close()
  bos.toByteArray
}

// * `CachedFactory` takes two type parameters, a `K` key type and a `V` value type.
//   In this case `K` is `Unit` since all `ByteArrayOutputStream`s are the same, but if you
//   are caching things which take some kind of configuration (e.g. compilers with compiler
//   flags) you can set `K` to be the config class so that values with different input
//   configuration are cached separately.
//
// * `setup` creates the `ByteArrayOutputStream`, `maxCacheSize` configures the maximum
//   number of cached entries to keep around while they are not in use, and when the count
//   of cached entries exceeds that number `teardown` cleans them up
//
// Although this example is synthetic (you don't actually need to reset, reuse, and teardown
// `ByteArrayOutputStream`s) the same techniques would apply to any long-lived mutable state
// or components you need to manage. This is especially important when
// xref:extending/running-jvm-code.adoc[running JVM code in classloaders or subprocesses],
// as those are both expensive to initialize and need to be properly closed or terminated
// when you are done with them
//
// The above `cachedCompressWorker` can be used as shown below, with three
// `def compressed*` tasks using it to call `.compress`:

def compressed1 = Task {
  cachedCompressWorker().compress("foo.txt", "I am cow".getBytes)
}

def compressed2 = Task {
  cachedCompressWorker().compress("bar.txt", "Hear me moo".getBytes)
}

def compressed3 = Task {
  cachedCompressWorker().compress("qux.txt", "I weigh twice as much as you".getBytes)
}

/** Usage

> # 3 streams are created on demand, 1 is torn down afer due to maxCacheSize = 2 limit
> ./mill show '{compressed1,compressed2,compressed3}'
setup ByteArrayOutputStream
setup ByteArrayOutputStream
setup ByteArrayOutputStream
Compressing: foo.txt
Compressing: bar.txt
Compressing: qux.txt
teardown ByteArrayOutputStream
{
  "compressed1": ...
  "compressed2": ...
  "compressed3": ...
}

> # `clean` clears the CachedFactory and tears down the two streams in the cache
> ./mill clean cachedCompressWorker
teardown ByteArrayOutputStream
teardown ByteArrayOutputStream

*/
