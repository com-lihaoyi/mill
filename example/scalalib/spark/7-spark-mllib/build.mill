package build
import mill._, scalalib._

object `package` extends RootModule with ScalaModule {
  def scalaVersion = "2.12.15"
  def ivyDeps = Seq(
    ivy"org.apache.spark::spark-core:3.5.4",
    ivy"org.apache.spark::spark-sql:3.5.4",
    ivy"org.apache.spark:spark-mllib_2.12:3.5.4"
  )

  def forkArgs = Seq(
    "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED",
    "--add-opens=java.base/java.nio=ALL-UNNAMED",
    "--add-opens=java.base/java.util=ALL-UNNAMED",
    "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED"
  )

  def prependShellScript = ""

  object test extends ScalaTests {
    def ivyDeps = Seq(ivy"com.lihaoyi::utest:0.8.5")
    def testFramework = "utest.runner.Framework"

    def forkArgs = Seq(
      "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED",
      "--add-opens=java.base/java.nio=ALL-UNNAMED",
      "--add-opens=java.base/java.util=ALL-UNNAMED",
      "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED"
    )
  }

}

/** Usage

> ./mill run
...
VALIDATION: Starting Spark MLlib Pipeline
VALIDATION: Spark session initialized successfully
VALIDATION: Loading data from path: .../resources/data.csv...
VALIDATION: Training new model
VALIDATION: Model accuracy = ...
VALIDATION: Model AUC = ...
VALIDATION: Model persistence validated at ./out/dt_model
VALIDATION: Spark session closed
...

> ./mill test
...foo.FooTests.dataLoading...
...foo.FooTests.pipelineConstruction...
...foo.FooTests.modelTraining...
...foo.FooTests.modelPersistence...
...foo.FooTests.evaluationMetrics...
...Tests: 5, Passed: 5, Failed: 0...

*/
