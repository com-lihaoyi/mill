//// SNIPPET:CRAWLER
//
// Below is another web crawler, but instead of crawling Wikipedia's HTML pages using JSoup,
// it uses https://github.com/Kotlin/kotlinx.serialization[KotlinX-Serialization],
// https://github.com/Kong/unirest-java[Unirest-Java], and https://github.com/ajalt/clikt[Clikt], to write a
// program that crawls wikipedia and saves the crawl results to a file:

/** See Also: JsonApiClient.kt */

/** Usage
> ./mill JsonApiClient.kt --start-article singapore --depth 2

> cat fetched.json
[
    "Calling code",
    "+65",
    "British Empire",
    "1st Parliament of Singapore",
    ...
]

*/
