// tag::header[]

# Invalidating build caches using JVM bytecode callgraph analysis

:author: Li Haoyi
:revdate: ??? March 2025

_{author}, {revdate}_

Build tools often cache your task outputs and invalidate them when the input
files change, and build tools often let you implement tasks using blocks of arbitrary
code in some general-purpose language. But the combination of these raises a
question: if your tasks can contain arbitrary code, how can you detect when that code
is changed, and invalidate the task's caches? In most programming languages, "blocks
of arbitrary code" are opaque - and the only thing you can do is run them - so
this problem is unsolvable.

This blog post explores how Mill extends its JVM runtime by analyzing the callgraph of your
build logic at a JVM-bytecode level. This allows Mill to analyze a task's code-block to detect
when the implementation of a task is affected by changes in its source code or
transitively-called methods, allowing us to invalidate task caches when the code used by a
task is modified. We'll discuss the implementation and limitations of this bytecode analyses,
and show empirically how this is able to provide a significant improvement over more naive
approaches to the problem.

// end::header[]

## Source File and Code Change Invalidation

To illustrate this problem, consider the following `build.mill` config:

```scala
def fooSource = Task.Source("foo.txt")
def fooTask: T[String] = Task{
  println("evaluating fooTask")
  os.read(fooSource().path).toUpperCase
}

def barSource = Task.Source("bar.txt")
def barHelper(s: String) = s.toUpperCase
def barTask: T[String] = Task{
  println("evaluating barTask")
  barHelper(os.read(barSource().path))
}
```


This generates a build graph that looks like the following:

```graphviz
digraph G {
  rankdir=LR
  node [shape=box width=0 height=0]
  fooSource -> fooTask
  barSource -> barTask
}
```

If you run this for the first time, you can see the `println`s indicating both
tasks evaluated:

```bash
> ./mill show '{fooTask,barTask}'
evaluating fooTask
evaluating barTask
{
  "fooTask": "FOO.TXT CONTENTS",
  "barTask": "BAR.TXT CONTENTS"
}
```

If you then run it again after changing `foo.txt`, you will see that only `fooTask` re-evaluates,
and `barTask` does not:

```bash
> echo " changed" >> foo.txt

> ./mill '{fooTask,barTask}'
evaluating fooTask
{
  "fooTask": "FOO.TXT CONTENTS CHANGED",
  "barTask": "BAR.TXT CONTENTS"
}
```

So far so good. But what if instead of changing the `foo.txt` or `bar.txt` source files,
we instead change the `build.mill` configuration itself?

For example, we may change the `.toUpperCase` to `toLowerCase`:

```diff
 def fooTask: T[String] = Task{
   println("evaluating fooTask")
-   os.read(fooSource().path).toUpperCase
+   os.read(fooSource().path).toLowerCase
 }
```

If you make this change, you would want `fooTask` to re-evaluate since its implementation
changed, but `barTask` to not re-evaluate since because nothing we changed affected it:

```bash
> ./mill show '{fooTask,barTask}'
evaluating fooTask
{
  "fooTask": "foo.txt contents",
  "barTask": "BAR.TXT CONTENTS"
}
```

Consider another case: what if instead of changing `fooTask`, I change `barHelper`:

```diff
-def barHelper(s: String) = s.toUpperCase
+def barHelper(s: String) = s.toLowerCase
```

This isn't directly changing any of the tasks `fooTask` or `barTask`, but instead
changes the `barHelper` helper method that is called by `barTask`. Again, we would
want `barTask` to re-evaluate to make use of the new helper method, but `fooTask`
should not re-evaluate because nothing we changed affected it.

```bash
> ./mill show '{fooTask,barTask}'
evaluating barTask
{
  "fooTask": "FOO.TXT CONTENTS",
  "barTask": "bar.txt contents"
}
```

That looks straightforward enough, so what's the issue?

## Why Code Change Invalidation is Hard

Mill `build.mill` files run on the JVM; the source code is written in Scala, but it
compiles to the same JVM bytecode that Java or Kotlin or any other JVM languages do.
When you look at the definition of a task such as:

```scala
def fooTask: T[String] = Task{
  println("evaluating fooTask")
  os.read(fooSource().path).toUpperCase
}
```

`Task` takes a "by-name" block argument of type `=> T`.

```scala
def Task[T](block: => T): Task[T] = ???
```

Essentially, this means when you call `Task{ ... }`, the `...` is wrapped in a zero-argument
function `() => ...` of type `Function0[T]` that you can call via `.apply(): T`:

```scala
def fooTask: T[String] = Task{ () =>
  println("evaluating fooTask")
  os.read(fooSource().path).toUpperCase
}
```

"By-name" parameters are just a convenient way to define blocks of runnable code without
needing to tediously repeat the `() =>` in front of every one, but for all intents and
purposes the effect is the same: you get a `Function0[T]` that you can call via `.apply`
to get the value out of it. This `Function0` is what lets Mill decide whether or not it
needs to run the code in the block: if the inputs to the task are unchanged, Mill can
simply re-use the previous value and avoid running the `Function0`, but if the inputs to
the task were modified then Mill can call `.apply` on the `Function0` to compute the latest
value.

So far so good. But the only thing that the `Function0` class lets you do is call `.apply()`
to compute the result value of type `T`! In particular, `Function0` does not let you inspect
the function to look at its source code or implementation: like function values in any
language all that is encapsulated and hidden away from you. How then can Mill detect that
the `.toUpperCase` in `fooTask` was replaced by `.toLowerCase`, so Mill knows to re-evaluate
`fooTask` even though `fooSource` was not modified? Or in the case of modifying `barHelper`,
how would Mill know to re-evaluate `barTask` even though `barSource` was not changed, and
even ``barTask``'s own code block was not changed?

## Common Approximations

Because deciding whether or not a code block or method implementation has changed is difficult,
most build tools punt on the problem entirely:

1. Early versions of Mill simply invalidated all caches globally if a build file was changed.
   This is conservatively correct - it will never invalidate too few caches! - but was definitely
   overkill since most changes to build files did not affect most tasks

2. Most other build tools like Maven, Gradle or SBT simply do not automate caching and invalidation,
   and leave it up to the implementor of the task to do so. That means the implementor has to do
   their own book-keeping keeping track of code versions and invalidating their own caches when
   the version changes. This is tedious and error prone, and often results in tasks not being cached
   or the cache invalidation being buggy (because deciding whether or not your code changes require
   caches to be invalidated can be very subtle and tricky!)

Both approaches are problematic: (1) is basically maximally conservative and pessimistic,
while (2) is basically maximally lasse-faire and optimistic. Neither approach is fatal -
and indeed people have lived with build tools working like this for decades - but we can
do better

## Basic Callgraph Analysis

The basic idea behind Mill's callgraph analysis is that JVM `Function0` objects
aren't actually opaque: if you would like to you could pull up the `.class` file
describing each object on disk. For example, consider `barTask`:

```scala
def barTask: T[String] = Task{
  println("evaluating barTask")
  barHelper(os.read(barSource().path))
}
```

We mentioned earlier that body of the `Task` block is wrapped in an anonymous `Function0`
`() => ...`. This anonymous function compiles to an `$$anonfun` method in the the bytecode
below:

```java
  private final mill.api.Result barTask$$anonfun$1$$anonfun$1(scala.collection.immutable.Seq, mill.api.Ctx);
    Code:
       0: getstatic     #183                // Field mill/api/Result$.MODULE$:Lmill/api/Result$;
       3: getstatic     #314                // Field scala/Predef$.MODULE$:Lscala/Predef$;
       6: ldc_w         #394                // String evaluating barTask
       9: invokevirtual #320                // Method scala/Predef$.println:(Ljava/lang/Object;)V
      12: aload_0
      13: getstatic     #325                // Field os/read$.MODULE$:Los/read$;
      16: aload_1
      17: iconst_0
      18: invokeinterface #330,  2          // InterfaceMethod scala/collection/immutable/Seq.apply:(I)Ljava/lang/Object;
      23: checkcast     #14                 // class mill/api/PathRef
      26: invokevirtual #334                // Method mill/api/PathRef.path:()Los/Path;
      29: invokevirtual #337                // Method os/read$.apply:(Los/ReadablePath;)Ljava/lang/String;
      32: invokevirtual #396                // Method barHelper:(Ljava/lang/String;)Ljava/lang/String;
      35: invokevirtual #278                // Method mill/api/Result$.create:(Ljava/lang/Object;)Lmill/api/Result;
      38: areturn
```

This bytecode contains a lot of `invokevirtual` and `invokeinterface` methods that specify,
after all the compiler's work is done, which methods in the JVM bytecode actually need to be
called. We can see the invocation of `scala/Predef$.println` and `os/read$` in the bytecode,
some `mill/api` helper methods, and also the call to `barHelper`.

```java
      32: invokevirtual #396                // Method barHelper:(Ljava/lang/String;)Ljava/lang/String;
```

We can also look at the `barHelper` method in the bytecode, which is defined as follows:


```java
  public java.lang.String barHelper(java.lang.String);
    Code:
       0: aload_1
       1: invokevirtual #165                // Method java/lang/String.toUpperCase:()Ljava/lang/String;
       4: areturn
```

``barHelper``'s bytecode contains a single call to `java/lang/String.toUpperCase`, which
is what we expect given its definition in the source code.

Just like the _build graph_ of tasks we described earlier, the calls between tasks and
normal methods in our build codebase also form a graph: a _call graph_. For the small
example snippet above, the (simplified) callgraph looks like this

```graphviz
digraph G {
  rankdir=LR
  node [shape=box width=0 height=0]
  fooTask
  barHelper -> barTask
}
```

The last thing we need to do is for each method, to do a breadth-first search to
find all transitively called methods, and hash their contents (the bytecode shown above).
For example, the change we saw earlier to the `barHelper` source code:

```diff
-def barHelper(s: String) = s.toUpperCase
+def barHelper(s: String) = s.toLowerCase
```

Would result in a corresponding change in the `barHelper` bytecode:

```diff
  public java.lang.String barHelper(java.lang.String);
    Code:
       0: aload_1
-      1: invokevirtual #165                // Method java/lang/String.toUpperCase:()Ljava/lang/String;
+      1: invokevirtual #165                // Method java/lang/String.toLowerCase:()Ljava/lang/String;
       4: areturn
```

The bytecode for a method is typically much more stable than the source code: it is not
affected by formatting, comments, some local variable names, etc.. This means that if
the bytecode for a method changes, it likely means the implementation changed, and any
tasks that call that method (directly or transitively) need to be re-evaluated.


## Object Oriented Callgraphs
Although the basic callgraph analysis on static methods shown above is straightforward,
in real code there is a lot of detail that needs to be dealt with. In particular, JVM
languages like Java and Scala make heavy use of objects, classes, and subclassing. These
add complications and complexity that aren't present in the static helper methods used
in earlier eamples



### Instance Methods

Consider the following example, replacing `barHelper` with a `classQux` containing a `def bazHelper`:

```scala
def barSource = Task.Source("bar.txt")
class Qux(suffix0: String) {
  val suffix = suffix0 + suffix0 + suffix0
  def bazHelper(s: String) = s.toUpperCase + suffix
}

def barTask: T[String] = Task{
  println("evaluating barTask")
  val qux = new Qux("!")
  qux.bazHelper(os.read(barSource().path))
} // BAR.TXT CONTENTS!!!
```

In this example, we are calling `bazHelper` on the value in `barTask`, but the behavior of
a `qux.bazHelper()` doesn't just depend on the implementation of `bazHelper`, but also:

1. The value `suffix` that was passed in when `new Qux` was constructed, in this case `!`
2. and the implementation of the `Qux#<init>` constructor, which assigns
   `val suffix = suffix0 + suffix0 + suffix0` to construct the `suffix` used in `bazHelper`

This turns out to work pretty well by default: the fact that you have `qux` means that you
must have called its constructor and passed in arguments (directly or indirectly):

```graphviz
digraph G {
  rankdir=LR
  node [shape=box width=0 height=0]
  "Qux#bazHelper" -> barTask
  "Qux#<init>" -> barTask
}
```

* Changes to the `Qux` constructor param `"!"` are part of the `barTask` task body
* Changes to the `Qux#<init>` constructor are captured because `Qux#<init>` is called by `barTask`
  to construct `qux` before using it
* Changes to `Qux#bazHelper` are captured because `bazHelper` is called by `barTask`

Thus, the existing callgraph is sufficient to detect any changes that affect instance methods

### Instance Fields

A similar approach can be take to analyzing fields, which are defined via the `val` keyword
in contrast to methods defined via `def`:

```scala
def barSource = Task.Source("bar.txt")
class Qux(suffix0: String) {
  var suffix = suffix0
  def doubleSuffix() = {
    suffix = suffix + suffix
  }
}

def barTask: T[String] = Task{
  println("evaluating barTask")
  val qux = new Qux("!")
  qux.doubleSuffix()
  qux.doubleSuffix()
  os.read(barSource().path) + qux.suffix
} // BAR.TXT CONTENTS!!!!
```

In this case, `barTask` references the `suffix` field directly, without going through
a `bazHelper` method. Method call graph analysis does not track fields, but it doesn't
need to: a field can only get its value from the methods that set it, whether
the constructor (above setting `var suffix = suffix0`) or other methods (e.g. `def doubleSuffix`,
which sets `suffix = suffix + suffix`).

```graphviz
digraph G {
  rankdir=LR
  node [shape=box width=0 height=0]
  "Qux#<init>" -> barTask
  "Qux#doubleSuffix" -> barTask
}
```

Since these methods are all already captured as part of the normal callgraph analysis
as a conservative approximation it's fine to ignore fields entirely: you will never
miss a code change that affects a field value because such code changes must occur in
methods which we already track.

### Enclosing Fields

A follow up example is what happens if the task block relies on a field (`val`) rather
than a method (`def`) in an enclosing object?

```scala
object enclosing extends Module{
  def barSource = Task.Source("bar.txt")
  val suffix = "???"
  def barTask: T[String] = Task{
    println("evaluating barTask")
    os.read(barSource().path) + suffix
  } // bar.txt contents???
}
```

In this case, it is clear that the transitive callgraph of `barTask` is not sufficient,
because not only do we need to call `barTask`, we first need to instantiate `object enclosing`
as well. This is similar to the <<Instance Methods>> case we looked at above, but instead of
relying on some object instance that `barTask` instantiates and calls, we are looking at
``barTask``'s _own_ object instance. But in both cases, we need to account for the constructor
code for the object on which we are calling the method.

In practice, this is straightforward: we just need to add an edge from the `enclosing#<init>`
(and any other enclosing objects) to `barTask` when constructing the callgraph:

```graphviz
digraph G {
  rankdir=LR
  node [shape=box width=0 height=0]
  "Qux#bazHelper" -> barTask
  "Qux#<init>" -> barTask
  "enclosing#<init>" -> barTask
}
```

Mill task methods can only live in ``Module``s, and ``Module``s instances can only be singleton
objects as part of the module tree. Thus they will all have a zero-arg `<init>` constructor
method.

### Virtual Methods

A single call to `java/io/InputStream.read()` may
call out to any number of methods various subclasses of `InputStream`. To resolve this,
you need to do a class hierarchy analysis
on the various classes in your program, so you can resolve such virtual callsite to possible
call definition sites in all possible subclasses.

There are varying degrees of precision for which you can analyze virtual methods, e.g.
_Class Hierarchy Analysis_ and _Rapid Type Analysis_ described in
[Fast Static Analysis of C++ Virtual Calls, OOPSLA96](https://courses.cs.washington.edu/courses/cse501/04wi/papers/bacon-oopsla96.pdf),
or even more sophisticated dataflow approaches such as [Points-To Analysis](https://en.wikipedia.org/wiki/Pointer_analysis)

At a high level, the distinction between these is in how they look for subclasses
that may provide an implementation for a virtual method. In order of increasing precision:

1. *Class Hierarchy Analysis*: Any class that implements that method globally in your codebase

2. *Rapid Type Analysis*: Any class that implements that method _that is instantiated as
   part of the program starting from the `main` entrypoint_

3. *Points-To Analysis*: Any class that
   implements that method that is _instantiated and passed to this specific callsite_

Mill uses a variant of (2) Rapid Type Analysis, with the tweak that with Mill `Task` may
serve as the entrypoint, rather than having a single global `main` method. This is less
precise than running the analysis separately for every `Task`, but has the advantage that
it can be done for the entire build in one pass rather than needing to repeat the analysis
for every `Task` separately.

## Other Complications




### Library Methods

In particular, we don't want to have to analyze the entire Java
standard library, because that would be very expensive. Mill thus only constructs a call graph
for local code, using a conservative approximation of calls to upstream libraries
(similar to that discussed in [Averroes: Whole-Program Analysis without the Whole Program,
ECOOP 2013](https://plg.uwaterloo.ca/~olhotak/pubs/ecoop13.pdf))

## Limitations

### No Data Flow analysis

The biggest limitation of using method _callgraph analysis_ to detect code changes affecting
tasks is the lack of _dataflow analysis_: we are simply aggregating all methods that get
called (transitively) by a task, but we don't actually know if those methods actually
affect the task output. For example, consider the following snippet:

```scala
def barSource = Task.Source("bar.txt")
class Qux(suffix0: String) {
  val suffix = suffix0 + suffix0 + suffix0
  def bazHelper(s: String) = s.toUpperCase + suffix
}

def barTask: T[String] = Task{
  println("evaluating barTask")
  val qux = new Qux("!")
  qux.bazHelper(os.read(barSource().path))
} // BAR.TXT CONTENTS!!!
```

The `Qux#<init>` method has the following bytecode:

```java
  public Qux(java.lang.String);
       0: aload_0
       1: invokespecial #13                 // Method java/lang/Object."<init>":()V
       4: aload_0
       5: new           #15                 // class java/lang/StringBuilder
       8: dup
       9: ldc           #16                 // int 0
      11: invokespecial #19                 // Method java/lang/StringBuilder."<init>":(I)V
      14: aload_1
      15: invokevirtual #23                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
      18: aload_1
      19: invokevirtual #23                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
      22: aload_1
      23: invokevirtual #23                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
      26: invokevirtual #27                 // Method java/lang/StringBuilder.toString:()Ljava/lang/String;
      29: putfield      #29                 // Field suffix:Ljava/lang/String;
      32: return
```

If we modify this by adding a second unused field:

```diff
 class Qux(suffix0: String) {
   val suffix = suffix0 + suffix0 + suffix0
+  val otherSuffix = suffix0 + suffix0
   def bazHelper(s: String) = s.toUpperCase + suffix
 }
```

This results in a corresponding change to the bytecode to initialize the new field:

```diff
  public Qux(java.lang.String);
       0: aload_0
       1: invokespecial #14                 // Method java/lang/Object."<init>":()V
       4: aload_0
       5: new           #16                 // class java/lang/StringBuilder
       8: dup
       9: ldc           #17                 // int 0
      11: invokespecial #20                 // Method java/lang/StringBuilder."<init>":(I)V
      14: aload_1
      15: invokevirtual #24                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
      18: aload_1
      19: invokevirtual #24                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
      22: aload_1
      23: invokevirtual #24                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
      26: invokevirtual #28                 // Method java/lang/StringBuilder.toString:()Ljava/lang/String;
      29: putfield      #30                 // Field suffix:Ljava/lang/String;
+     32: aload_0
+     33: new           #16                 // class java/lang/StringBuilder
+     36: dup
+     37: ldc           #17                 // int 0
+     39: invokespecial #20                 // Method java/lang/StringBuilder."<init>":(I)V
+     42: aload_1
+     43: invokevirtual #24                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
+     46: aload_1
+     47: invokevirtual #24                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
+     50: invokevirtual #28                 // Method java/lang/StringBuilder.toString:()Ljava/lang/String;
+     53: putfield      #32                 // Field otherSuffix:Ljava/lang/String;
      56: return
```

Which affects `barTask`, because our callgraph has `Qux#<init>` being called by `barTask`

```graphviz
digraph G {
  rankdir=LR
  node [shape=box width=0 height=0]
  "Qux#bazHelper" -> barTask
  "Qux#<init>" [penwidth=3 color=red]
  barTask [penwidth=3 color=red]
  "Qux#<init>" -> barTask [penwidth=3 color=red]
}
```

However, if you actually track the dataflow of the code, we would realize that
the field `otherSuffix` is not used by `barTask` at all! Only `suffix` is used.
Thus although our `Qux#<init>` was affected by the code change, `barTask` isn't
actually affected, and so invalidating `barTask` and forcing a re-evaluation would
be wasteful.

This is perhaps the largest gap in the callgraph analysis we present here: while
we are able to analyze the dependencies between _methods_ based on how they call each
other via `invokevirtual` or `invokespecial` bytecodes, we are unable to analyze
the dependencies between the _fields_ that those methods set. This can result in
false positives where changes to constructors or other methods cause our tasks
to invalidate unnecessarily.


### Reflection

Another major limitation in this analysis is that it assumes that all method calls
in your program are statically specified in the bytecode. This is not true of JVM applications
in general: anyone can call `getClass.getMethod(methodName).invoke()` with a dynamically
computed `methodName: String`, leaving static bytecode analysis with no way to figure out
what method is actually being called. Unlike the limitation above that results in false
positives, this limitation can result in false negatives where a method called by a
task changes and the task does not re-evaluate, because the method call happened via
`getMethod.invoke` which our analyzer cannot understand.

Although in theory this could be an issue, in typical Scala code (which `build.mill` files
are written in) runtime reflection is relatively rare. Scala codebases and libraries tend
to perform a lot of their work at compile-time: inferring types, resolving implicit parameters,
expanding macros, and so on. Although Scala's compile-time complexity is no less complicated than
the runtime reflection/classloading/classpath-scanning present in Java codebases, it has the
advantage that by the time we are looking at the JVM bytecode all the magic has already been
removed. Thus, we can analyze the JVM bytecode emitted by a Scala program with high confidence
that the callgraph defined in the bytecode gives a complete and accurate picture of how
the methods in the program call each other.


## Evaluation

### Precision



### Performance


Performance-wise, ad-hoc benchmarks on com-lihaoyi/mill's own build show a
~5% increase in build.sc compilation times due to this. Not nothing, but probably
acceptable: the cost is only paid when the build.sc is re-compiled, and it will
likely end up saving much more time in tasks that we can avoid running (e.g. a
single no-op Zinc incremental compile may be 100s of milliseconds)

|===
| | methodCodeHashSignatures | compile
| Cold | 685ms | 12,148ms
| Hot | 253ms | 4,143ms
|===

## Further Reading

Implementation PR https://github.com/com-lihaoyi/mill/pull/2417