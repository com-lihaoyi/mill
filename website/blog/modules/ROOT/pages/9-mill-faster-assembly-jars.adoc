// tag::header[]

# Faster JVM Assembly Jars with the Mill Build Tool

:author: Li Haoyi
:revdate: 13 February 2025

_{author}, {revdate}_

Assembly jars are a convenient deployment format for JVM applications, bundling
your application code and resources into a single file that can run anywhere a JVM
is installed. But assembly jars can be slow to create, which can slow down iterative
development workflows that depend on them. The Mill JVM build tool uses some special
tricks to let you iterate on your assembly jars much faster than traditional build tools
like Maven or Gradle, which can substantially increase your developer productivity.

// end::header[]

## Example JVM Application

For the purposes of this blog post, we will be using a small spark program
as our example application. This program was written by https://github.com/monyedavid[@monyedavid]
to demonstrate how to xref:mill:ROOT:scalalib/spark.adoc[Build Spark Programs using Mill],
and does some simple processing of a CSV file to output summary statistics:

```scala
package foo

import org.apache.spark.sql._
import org.apache.spark.sql.functions._

object Foo {
  case class Transaction(id: Int, category: String, amount: Double)

  def computeSummary(transactions: Dataset[Transaction]): DataFrame = {
    transactions.groupBy("category")
      .agg(
        sum("amount").alias("total_amount"),
        avg("amount").alias("average_amount"),
        count("amount").alias("transaction_count")
      )
  }

  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder()
      .appName("SparkExample")
      .master("local[*]")
      .getOrCreate()

    val resourcePath: String = args(0)

    import spark.implicits._

    val df = spark.read
      .option("header", "true")
      .option("inferSchema", "true")
      .csv(resourcePath)

    val transactionsDS: Dataset[Transaction] = df.as[Transaction]
    val summaryDF = computeSummary(transactionsDS)

    println("Summary Statistics by Category:")
    summaryDF.show()

    spark.stop()
  }
}
```

## Example Builds

### Mill

```scala
package build
import mill._, scalalib._

object `package` extends RootModule with SbtModule {
  def scalaVersion = "2.12.19"
  def ivyDeps = Agg(
    ivy"org.apache.spark::spark-core:3.5.4",
    ivy"org.apache.spark::spark-sql:3.5.4"
  )

  def forkArgs = Seq("--add-opens", "java.base/sun.nio.ch=ALL-UNNAMED")

  def prependShellScript = ""
}
```
```bash
 > ./mill show assembly
".../out/assembly.dest/out.jar"
Total time: 27s

$ ls -lh out/assembly.dest/out.jar
-rw-r--r--  1 lihaoyi  staff   214M Feb 14 15:51 out/assembly.dest/out.jar

> java --add-opens java.base/sun.nio.ch=ALL-UNNAMED -jar out/assembly.dest/out.jar src/main/resources/transactions.csv
...
+-----------+------------+--------------+-----------------+
|   category|total_amount|average_amount|transaction_count|
+-----------+------------+--------------+-----------------+
|       Food|        70.5|          23.5|                3|
|Electronics|       375.0|         187.5|                2|
|   Clothing|       120.5|         60.25|                2|
+-----------+------------+--------------+-----------------+
```


### SBT


```scala
lazy val root = (project in file("."))
  .enablePlugins(AssemblyPlugin) // Enables sbt-assembly
  .settings(
    name := "spark-app",
    version := "0.1",
    scalaVersion := "2.12.19"
    libraryDependencies ++= Seq(
      "org.apache.spark" %% "spark-core" % "3.5.4",
      "org.apache.spark" %% "spark-sql" % "3.5.4",
    ),
    assemblyMergeStrategy in assembly := {
      case PathList("META-INF", _ @ _*) => MergeStrategy.discard
      case _ => MergeStrategy.first
    }
  )
```
```bash
> sbt 'assembly'
Built: .../target/scala-2.12/spark-app-assembly-0.1.jar
Total time: 18 s

$ ls -lh target/scala-2.12/spark-app-assembly-0.1.jar
-rw-r--r--  1 lihaoyi  staff   213M Feb 14 15:58 target/scala-2.12/spark-app-assembly-0.1.jar

>  java --add-opens java.base/sun.nio.ch=ALL-UNNAMED -jar target/scala-2.12/spark-app-assembly-0.1.jar src/main/resources/transactions.csv
...
+-----------+------------+--------------+-----------------+
|   category|total_amount|average_amount|transaction_count|
+-----------+------------+--------------+-----------------+
|       Food|        70.5|          23.5|                3|
|Electronics|       375.0|         187.5|                2|
|   Clothing|       120.5|         60.25|                2|
+-----------+------------+--------------+-----------------+
```

### Maven

```xml
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.example</groupId>
    <artifactId>spark-app</artifactId>
    <version>0.1</version>
    <packaging>jar</packaging>

    <properties>
        <scala.version>2.12.19</scala.version>
        <spark.version>3.5.4</spark.version>
        <maven.compiler.source>1.8</maven.compiler.source>
        <maven.compiler.target>1.8</maven.compiler.target>
    </properties>

    <dependencies>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_2.12</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_2.12</artifactId>
            <version>${spark.version}</version>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <!-- Maven Assembly Plugin for creating a fat JAR -->
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-assembly-plugin</artifactId>
                <version>3.6.0</version>
                <configuration>
                    <descriptorRefs><descriptorRef>assembly</descriptorRef></descriptorRefs>
                    <archive><manifest><mainClass>foo.Foo</mainClass></manifest></archive>
                </configuration>
                <executions>
                    <execution>
                        <id>make-assembly</id>
                        <phase>package</phase>
                        <goals>
                            <goal>single</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>

            <!-- Compiler Plugin -->
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.8.1</version>
                <configuration>
                    <source>${maven.compiler.source}</source>
                    <target>${maven.compiler.target}</target>
                </configuration>
            </plugin>

            <!-- Scala Plugin -->
            <plugin>
                <groupId>net.alchim31.maven</groupId>
                <artifactId>scala-maven-plugin</artifactId>
                <version>4.7.1</version>
                <executions>
                    <execution>
                        <goals>
                            <goal>compile</goal>
                            <goal>testCompile</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
</project>
```
```bash
> ./mvnw package -DskipTests
Building jar: .../target/spark-app-0.1-jar-with-dependencies.jar
Total time:  20 s

> ls -lh target/spark-app-0.1-jar-with-dependencies.jar
-rw-r--r--  1 lihaoyi  staff   211M Feb 14 16:12 target/spark-app-0.1-jar-with-dependencies.jar

> java --add-opens java.base/sun.nio.ch=ALL-UNNAMED -jar target/spark-app-0.1-jar-with-dependencies.jar src/main/resources/transactions.csv
...
+-----------+------------+--------------+-----------------+
|   category|total_amount|average_amount|transaction_count|
+-----------+------------+--------------+-----------------+
|       Food|        70.5|          23.5|                3|
|Electronics|       375.0|         187.5|                2|
|   Clothing|       120.5|         60.25|                2|
+-----------+------------+--------------+-----------------+
```

We can see all 3 build tools take about 20s to build the assembly, with some
variation expected from run to run. All three jars are about the same size (~212mb),
which makes sense since they should contain the same local code and upstream dependencies.
While 20s is a bit long, it's not that surprising since the tool has to compress
a large ~212mb jar file.

NOTE: for many Spark usage patterns, e.g. https://spark.apache.org/docs/latest/submitting-applications.html[spark-submit],
you do not need to include `spark-core` and `spark-sql` in the assembly jar you
submit to the cluster, as the cluster will provide them. Nevertheless, any Spark or JVM
developer will likely encounter scenarios where large assemblies are necessary,
whether due to third-party libraries or non-spark frameworks. Similarly, although
the example Spark code is in Scala, the same techniques apply to any JVM language
that compiles to bytecode you may want to pack into an assembly.

## Incremental Builds

While all JVM build tools take about the same amount of time for the initial build,
what is interesting is what happens for incremental builds. For example, below we
add a `class dummy` line of code to `Foo.scala` to force it to re-compile:

```bash
> echo "class dummy" >> src/main/scala/foo/Foo.scala

> ./mill show assembly
".../out/assembly.dest/out.jar"
1s

> sbt assembly
Built: .../target/scala-2.12/spark-app-assembly-0.1.jar
Total time: 20 s

> ./mvnw package
Building jar: .../target/spark-app-0.1-jar-with-dependencies.jar
Total time:  22 s
```

Here, we can see that Mill only took `1s` to re-build the assembly jar,
while SBT and Maven took the same ~20s that they took the first time the
jar was built. If you play around with it, you will see that the assembly jar
does contain classfiles associated with our newly-added code:

```bash
> jar tf out/assembly.dest/out.jar | grep dummy
foo/dummy.class

> jar tf target/scala-2.12/spark-app-assembly-0.1.jar | grep dummy
foo/dummy.class

> jar tf target/spark-app-0.1-jar-with-dependencies.jar | grep dummy
foo/dummy.class
```

You can try making other code changes, e.g. to the body of the spark program itself,
and running the output jar with `java -jar` to see that your changes are indeed
taking effect. So the question you may ask is: how is it that Mill is able to
rebuild it's output assembly jar in ~1s, while other build tools are
spending a whole ~20s rebuilding it?

## Copy-On-Update Jar Files

The trick to Mill's fast incremental rebuilding of assembly jars is to split the
assembly jar creation into two phases. Mill calls these `upstreamAssembly` and `assembly`:

```scala
/**
 * Build the assembly for upstream dependencies separate from the current
 * classpath
 *
 * This should allow much faster assembly creation in the common case where
 * upstream dependencies do not change
 */
def upstreamAssembly: T[Assembly] = Task { ... }

/**
 * An executable uber-jar/assembly containing all the resources and compiled
 * classfiles from this module and all it's upstream modules and dependencies
 */
def assembly: T[PathRef] = Task { ... }
```

`upstreamAssembly` is a jar file containing all the files taken from upstream
dependencies: both upstream local modules on disk, as well as third-party dependencies
from Maven Central such as `spark-core` and `spark-sql`. In many applications,
this `upstreamAssemblyClasspath` is bulk of the data in your assembly jar.
and also changes relatively infrequently: someone may be adding `println`s and
iterating on their local code once every few seconds, while they may change
their upstream dependencies once every few days or less.

The next trick is that rather than building the `assembly` jar from scratch,
Mill instead:

1. Makes a copy of the `upstreamAssemblyJar`, which is fast even when the file is large

2. Opens that copy using `java.nio.file.FileSystems.newFileSystem`, which allows you
   to open an existing jar file by passing in `new URI("jar", path, null)`

3. Modifies the returned `java.nio.file.FileSystem` using normal `java.nio.file.File`
   operations

Since `.jar` files are just `.zip` files by another name, calling `FileSystems.newFileSystem`
with a `"jar"` URL returns a
https://github.com/openjdk/jdk/blob/master/src/jdk.zipfs/share/classes/jdk/nio/zipfs/ZipFileSystem.java[ZipFileSystem].
`ZipFileSystem` basically implements all the normal `java.nio.file.File.*` operations that
normally modifies files on disk, and replaces them with versions to instead modify
the entries inside a `.zip` file. And since `.zip` files have every file individually
compressed (unlike e.g. `.tar.gz` which compresses them together) `ZipFileSystem` is
able to efficiently read and write individual files to the `zip` file without needing
to un-pack and re-pack the entire archive.

Exactly how the `ZipFileSystem` works is beyond the scope of this article, and
may change over time as the Java platform evolves. But what is important is that it
allows Mill to incrementally update its assembly jars in _O(size-of-local-code)_,
rather than _O(size-of-transitive-dependencies)_.

## Possible Future Work

One possible optimization that Mill does not yet do is to use the _previous_ `assembly`
jar as the base to copy-and-modify, rather than the `upstreamAssembly`. This would
help further improve performance when your local codebase is large, as even in large
codebases the developer tend to change only a few files at a time, and it should be
possible to compare the local files before and after each change to decide which
files need to be updated in the assembly.

## Conclusion

This blog post has discussed how Mill is able to provide fast incremental updates to
generated assembly jars, allowing the developer to make local changes and get the same
output artifact much faster than with other build tools like Maven or SBT. In the example
shown above it sped up Spark assembly jar creation from ~20s to ~1s, but the speedup can
apply to any JVM codebase, and the benefit would depend on the size of your local application
code and its transitive dependencies. More sophisticated update schemes are also possible,
which would extend this optimization to scenarios where most of the assembly size comes
from local code rather than from upstream dependencies.

It turns out there's no magic in Mill's fast assembly generation: just careful use of
the available APIs provided by the underlying JVM platform.
