= Comparing Mill vs Gradle

Gradle is a popular open source build tool in the Java and JVM ecosystem,
second only to Maven. Gradle's core API is built around programmable configuration
files written in Groovy or Kotlin. Mill also provides programmable configuration
in its `build.mill` syntax, but thanks to its xref:#_object_oriented_builds[object-oriented builds]
Mill is able to provide a much more familiar programming experience with much better
IDE support than Gradle has been able to do.

== Extending Mill

Mill defaults to a declarative xref:javalib/intro.adoc#_config_based_modules[config-based module syntax],
but when you do need to extend it Mill's
xref:javalib/intro.adoc#_programmable_modules[programmable module syntax] allows you to directly
write code to configure your build, and make it do exactly what you want.

Most build tools need plugins to do anything: if you want to _Foo_ you need a
_Foo plugin_, if you want to Bar you need a _Bar plugin_, for any possible _Foo_ or _Bar_. These could
be simple tasks - zipping up files, pre-rendering web templates, preparing static assets for
deployment - but even a task that would be trivial to implement in a few lines of code requires
you to Google for third-party plugins, dig through their Github to see which one is best
maintained, and hope for the best when you include it in your build. And while you could
write plugins yourself, doing so is usually non-trivial.

Mill is different. Although Mill does have
xref:extending/thirdparty-plugins.adoc[plugins supporting common integrations],
for most simple things you can directly write code to achieve what you want using the bundled
filesystem, subprocess, and dependency-management libraries. And even if you need third-party
libraries from Maven Central to do `xyz`, you can directly import the "`xyz`" library and use it
directly, without having to find a "xyz build plugin" wrapper.

=== Simple Custom Tasks

The following Mill build is a minimal Java module `foo`. It contains no custom configuration, and
so inherits all the defaults from `mill.javalib.JavaModule`: default source folder layout, default
assembly configuration, default compiler flags, and so on. This _convention over configuration_
is a philosophy that Mill inherited from Maven and other JVM build tools:

[source,scala]
----
package build
import mill.*, javalib.*

object foo extends JavaModule {
}
----

[source,console]
----
> mill compile
Compiling 1 Java source...
----

If you want to add a custom task, this is as simple as defining a method e.g.
`def lineCount = Task { ... }`. The body of `Task` performs the action we want, and
can depend on other tasks such as `allSourceFiles()` below:

[source,scala]
----
package build
import mill.*, javalib.*

object foo extends JavaModule {
  /** Total number of lines in module source files */
  def lineCount = Task {
    allSourceFiles().map(f => os.read.lines(f.path).size).sum
  }
}
----

Once we define a new task, we can immediately begin using it in our build.
`lineCount` is not used by any existing `JavaModule` tasks, but we can still
show its value via the Mill command line to evaluate it, or inspect its metadata:

[source,console]
----
> ./mill show foo.lineCount
17

> ./mill inspect foo.lineCount
foo.lineCount(build.mill:4)
    Total number of lines in module source files

Inputs:
    foo.allSourceFiles
----

Note that as `lineCount` is a `Task`, we get automatic caching, invalidation, and
parallelization: these are things that every `Task` gets for free, without the task
author to do anything. And although we wrote the `lineCount` logic in the main
`build.mill` file for this example, if it grows complex enough to get messy it is
easy to move it to your own xref:extending/writing-plugins.adoc[custom plugins]

=== Overriding Tasks

To wire up `lineCount` into our main `JavaModule` `compile`/`test`/`run` tasks,
one way is to take the line count value and write it to a JVM resource file
to be used at runtime. In Mill your JVM resources are just a method `def resources`,
so we can override it and make it depend on `lineCount`, in addition
to its prior value `super.resources()` (that references the `resources/` folder on disk):

[source,scala]
----
package build
import mill.*, javalib.*

object foo extends JavaModule {
  /** Total number of lines in module source files */
  def lineCount = Task {
    allSourceFiles().map(f => os.read.lines(f.path).size).sum
  }

  /** Generate resources using lineCount of sources */
  override def resources = Task {
    os.write(Task.dest / "line-count.txt", "" + lineCount())
    super.resources() ++ Seq(PathRef(Task.dest))
  }
}
----


Because our `def resources` overrides the existing `resources` method inherited from `JavaModule`,
the downstream tasks automatically now use the new override instead, similar to any Java
method overrides. That means if you call `mill foo.run`, it will automatically pick up the new
`resources` including the generated `line-count.txt` file and make it available to
the application code to use e.g. to print it out at runtime:

[source,console]
----
> mill foo.run
Line Count: 18
----

Next, we'll look at a more realistic example,
which includes usage of third-party libraries in the build.

=== Using Third-Party JVM Libraries in Tasks

Many build tasks require third-party libraries. One example is pre-rendering HTML pages
in the build so they can be served at runtime: if a page never changes, rendering it on every request is
wasteful, and even rendering it once on startup and then caching it
can impact your application startup time. Thus, you may want to move some HTML rendering to
build-time, but with traditional build tools such a move is sufficiently inconvenient and
complicated that people rarely do it. Other use cases may include custom linters, custom
deployment artifacts, custom debugging metadata, and so on.

With Mill, using third-party libraries in your build tasks is very easy. Mill does not
ship with a bundled HTML templating engine, but you can use the
xref:extending/import-mvn-plugins.adoc[//| mvnDeps] syntax to include one such as
https://www.thymeleaf.org/[Thymeleaf], which would immediately make the
Thymeleaf classes available for you to import and use in your build as below:

[source,scala]
----
//| mvnDeps:
//| - org.thymeleaf:thymeleaf:3.1.1.RELEASE
package build

import mill.*, javalib.*
import org.thymeleaf.TemplateEngine
import org.thymeleaf.context.Context

object foo extends JavaModule {
  /** Total number of lines in module source files */
  def lineCount = Task {
    allSourceFiles().map(f => os.read.lines(f.path).size).sum
  }

  def htmlSnippet = Task {
    var context = new Context()
    context.setVariable("heading", "Line Count is: " + lineCount())
    new TemplateEngine().process(
        "<h1 th:text=\"${heading}\"></h1>",
        context
    )
  }

  def resources = Task {
    os.write(Task.dest / "snippet.txt", htmlSnippet())
    super.resources() ++ Seq(PathRef(Task.dest))
  }
}
----

Once we have specified our `//| mvnDeps` in the build file YAML header, we can import
`TemplateEngine`, `Context`, and follow our `def lineCount` with a `def htmlSnippet` task
that uses Thymeleaf to render HTML. We get full IDE support for working with the
Thymeleaf Java API, the new `htmlSnippet` task is inspectable from the Mill command line
via `show`, and we wire it up into `def resources` so it can be inspected and used at
runtime by the application (in this case just printed out):

image::why-mill/ExtendingIDESupport.png[]

[source,console]
----
> mill show foo.htmlSnippet
"<h1>Line count is: 17</h1>"

> mill foo.compile
compiling 1 Java source...
...

> mill foo.run
generated snippet.txt resource: <h1>Line count is: 17</h1>
----

Rendering HTML using the Thymeleaf templating engine is not rocket science, but what is
interesting here is what we did _not_ need to do:

* We did _not_ need to find a Thymeleaf-Mill plugin in order to include Thymeleaf in our
build

* We did _not_ need to learn a special API or framework for authoring build plugins ourselves
to write a plugin to include Thymeleaf in our build

* We did _not_ need to add fragile shell scripts to augment our build logic and
implement the functionality we need.


Instead, we could simply import Thymeleaf as a Java library directly from Maven Central
and use it just like we would use it in any Java application, with IDE support,
typechecking, and all the necessary build tool features like automatic parallelism, caching,
and invalidation.

=== Mill vs Gradle Configuration as Code

It's worth contrasting the Mill config above with e.g. the equivalent Gradle configuration
for setting up a line-count resource file:

[,kotlin]
----
import java.io.File

tasks.register("generateLineCount") {
    val sourceDirs = listOf("src/main/java")
    val outputDir = layout.buildDirectory.dir("generated-resources")
    val outputFile = outputDir.get().file("line-count.txt")

    inputs.files(fileTree("src/main"))
    outputs.file(outputFile)

    doLast {
        var totalLines = 0

        sourceDirs.map(::file).filter { it.exists() }.forEach { srcDir ->
            srcDir.walkTopDown()
                .filter { it.isFile && it.extension in listOf("java") }
                .forEach { file ->
                    totalLines += file.readLines().size
                }
        }

        outputFile.asFile.writeText(totalLines.toString())
        println("Generated line-count.txt with $totalLines lines")
    }
}

tasks.named("processResources") {
    dependsOn("generateLineCount")
    from(layout.buildDirectory.dir("generated-resources"))
}
----

While the Gradle config is a bit more verbose than Mill's, that is not where the problem
lies. The problem lies in the fact that the Gradle "config as code" doesn't _actually_
look like the code you are writing day-to-day: although it is written in Kotlin,
things like `task.named`, `dependsOn`, `inputs.files` and `outputs.file`, `doLast`
(or should we use `doFirst`?) are not "normal" Kotlin. The stringly-typed `"generateLineCount"`,
`"generated-resources"`, `"processResources"`, values add to the potential for error.
The end result is that although you may know Kotlin as a compiled language with great
IDE support, you will likely be unfamiliar with Gradle's flavor of Kotlin, and your
IDE will likely not be as useful as you would like.

In fact, there is even a bug in the above Gradle config that will cause the build to
be non-deterministically slower sometimes, but not other times.
Can you spot it?

The difficulty of catching these issues e.g. during code review
illustrates how difficult it is to write "correct" Gradle config: if even the simplest
hello-world customization results in impossible-to-find bugs slowing things down, how many
bugs will there be in any more-complex real-world customization or plugin? It's no wonder
then than real-world builds using Gradle or other tools often end up being inexplicably
slow and flaky!
(Click the footnote to see the answer footnote:[The bug is `inputs.files` is depending on `src/main`, when it only really needs
`src/main/java`. That means that changes to `src/main/resources` or `src/main/templates`
will cause the task redundantly re-compute, making your build slower than necessary. If the bug was the other way -
rather than depending on too large a folder instead depending on too small a folder -
it would instead cause flakiness where `generateLineCount` would sometimes not run when it needs to.])

In contrast, Mill's `extends`, method ``def``s and method calls, and `overrides`
behave exactly as you would expect any object-oriented program to work, so you already
know how Mill behaves even if you've never touched a Mill build before. And the fact
that Mill build config is so much easier to write means that you're much less likely
to have bugs causing slowness or flakiness, resulting in the improved performance
(discussed above) and not needing to regularly run `clean` as you often have to do with other
build tools.

'''

Most real projects require some kind of ad-hoc build tasks: you may be pre-processing static
assets for web deployment, embedding build metadata for runtime debugging, or generating
reports for security scanning. With most build tools, you often needed to pull
in some poorly-maintained plugin off of Github, write your own using a complicated plugin
framework, or even wrap your build tool in ad-hoc shell scripts. With most other build tools,
caching and parallelism are things that the build or plugin author needs to set up manually,
meaning everyone makes mistakes and your build system performance is never as good as it could be.

In contrast, Mill makes it easy it is to write concise type-checked code to perform ad-hoc tasks
to do whatever you need to do. You get full IDE support, automatic caching and
parallelism, and access to the huge JVM library ecosystem on Maven Central.
Rather than grabbing unmaintained plugins off of Github or augmenting your build
with fragile shell scripts, Mill allows your own custom logic to be implemented
in a way that is flexible, performant, and safe, such that anyone can configure their
build correctly and achieve maximum performance even without being a build tool expert.

== IDE Support

One area that Mill does better than Gradle is in providing a seamless IDE
experience. Working with Mill builds in IntelliJ or VSCode, you get the full power of
your IDE to autocomplete, peek at docs, browse signatures, and otherwise navigate
around your build system. Working with your Mill build, you get the same level of
IDE support as working within any Java, Scala, or Kotlin application codebase.

image:comparisons/IntellijOverrideAutocomplete.png[]

=== Limitations of Existing Build Tool IDE Integrations

While JVM application codebases universally have excellent IDE support, build tools are usually
not nearly as well-supported. For example, consider the snippet below where we are using Gradle to
configure the javac compiler options. The autocomplete and code-assist experience working
with these files is hit-or-miss. In the example below, we can see that IntelliJ is able to
identify that `compileArgs` exists and has the type `List<String>`:

image:comparisons/IntellijMockitoGradleCompileOptions.png[]

But if you try to jump to definition or find out anything else about it you hit a wall.
The IDE is able to bring you to the getter and setter, but it isn't able to tell you
_where the value is coming from_, _how it is computed_, or _where it is used_:

image:comparisons/IntellijMockitoGradleCompileOptions2.png[]

Often working with build configurations feels like constantly hitting a wall: if you
don't have `options.compilerArgs` memorized in your head, there is literally nothing
you can do in your IDE to figure out what it is or what it is used for. That leaves
you Googling for answers or digging through stackoverflow, which can be a frustrating
experience. Even modern AI assistants like ChatGPT or Gemini often hallucinate and get
things wrong.

Although this example is using Gradle's un-typed Groovy syntax, the experience
using Gradle's typed Kotlin syntax is largely the same. The problem isn't unique
to Gradle, and isn't unique to IntelliJ: any IDE would have similar problems working
with this code. The problem is the build tool configuration itself, or rather the
style of code that most build tools require they be configured with.

=== Global Mutable Variables

The fundamental problem with build tools like Gradle is that the entire configuration system
is based around _global mutable variables_. The Groovy or Kotlin code you write does not
actually _perform the build_, but instead is just setting up some
global mutable data structure that is used to configure the _real_ build engine that
runs _later_. Thus when you explore the Gradle build in an IDE, the IDE can only explore the
configuration logic (the `getCompilerArgs` method above) and is unable to explore
the actual build logic (how `getCompilerArgs` _actually gets used in Gradle_). And
just because the global mutable variable is wrapped in a getter and setter
does not make it any less global or any less mutable!

The problem with IDEs not being able to understand code written with global mutable
variables is not new. If you wrote your application code primarily using global mutable
variables, your IDE would not be able to help you much there either! So nobody does that,
and instead applications are primarily built using classes and methods, but some how
no build tool follows the same style so they all have problems with IDEs not being able
to work with their global mutable variables effectively.

=== The Mill IDE Experience


In comparison, not only are Mill's `.mill` files statically typed, they are
built on top of _classes_ and _methods_ like any other JVM codebase. While IDEs struggle
with global variables, they are very good at navigating classes and methods!
For example IntelliJ is able to take your `def javacOptions` override and
find the original definitions that were overridden, and show you where they are defined:

image::comparisons/IntellijMockitoMillJavacOptionsParents.png[]

You can jump to any of the overridden ``def``s quickly and precisely:

image::comparisons/IntellijMockitoMillJavacOptionsDef.png[]

And because tasks in Mill are just normal methods, IntelliJ is
able to _find usages_, showing you where the task is used. Below, we can see the method
call in the `def compile` task, which uses `javacOptions()` along with a number of other tasks:

image::comparisons/IntellijMockitoMillCompile.png[]

From there, if you are curious about any of the other tasks used alongside `javacOptions`, it's
easy for you to pull up _their_ documentation, jump to _their_
definition, or find _their_ usages. For example we can pull up the docs of
`compileClasspath()` below, jump to _its_ implementation, and continue
interactively exploring your build logic from there:

image::comparisons/IntellijMockitoMillCompileClasspath.png[]

Unlike most other build tools, Mill build pipelines can be explored interactively in your
IDE. If you do not know what something does, it's documentation, definition, or usages is always
one click away in IntelliJ or VSCode. This isn't a new experience for Java developers, as it
is what you experience every day working in your application code! But Mill brings that same
polished experience to your build system - traditionally something that has been opaque
and hard to understand - and does so in a way that no other build tool does. And this is
possible because Mill builds avoid the global mutable variables common in other build
tools, in favor of configuring your build via classes and methods that are familiar to
both users and to IDEs.

== Object-Oriented Builds

Mill has a lot of improvements over build tools like Maven or Gradle, but it begs the
question: why can't other build tools improve performance, extensibility, IDE support
as well? It turns out that other tools _have_ been working on improving performance,
extensibility and IDE support - for decades in the case of Maven or Gradle - but Mill
does have secret sauce that makes providing this experience in Mill much easier than
providing it in any other build tool.

All build tools are complex, because the requirements of building any size-able real-world
project are complex. One big source of build tool complexity is that users need some way to
define templated, customizable graph-computations when setting up their build pipelines.

- *Computations* as you need to specify what each build step does
- *Graph* as the data structure necessary to order and parallelize steps in your build
- *Templated* as different modules in a build are often very similar, with similar pipelines
- *Customizable* as there are always some module, or group of modules, special in some way

For example, even a simplified three-module Java build pipeline may look like this:

[graphviz]
....
digraph G {
  rankdir=LR
  node [shape=box width=0 height=0 style=filled fillcolor=white]
  bgcolor=transparent
  newrank=true;
  subgraph cluster_0 {
    style=dashed
    node [shape=box width=0 height=0 style=filled fillcolor=white]
    label = "foo";
    "foo.sources"
    "foo.compile"
    "foo.mainClass"
    "foo.assembly"
    "foo.classPath"
  }
  subgraph cluster_1 {
    style=dashed
    node [shape=box width=0 height=0 style=filled fillcolor=white]
    label = "bar";
    "bar.sources"
    "bar.compile"
    "bar.mainClass"
    "bar.assembly"
    "bar.classPath"
  }
  subgraph cluster_2 {
    style=dashed
    node [shape=box width=0 height=0 style=filled fillcolor=white]
    label = "qux";
    "qux.sources"
    "qux.compile"
    "qux.mainClass"
    "qux.assembly"
    "qux.classPath"
  }
  "foo.sources" -> "foo.compile" -> "foo.classPath" -> "foo.assembly"
  "foo.mainClass" -> "foo.assembly"
  "foo.classPath" -> "bar.compile"   [constraint=false];

  "foo.classPath" -> "bar.classPath"
  "bar.mainClass" -> "bar.assembly"
  "bar.sources" -> "bar.compile" -> "bar.classPath" -> "bar.assembly"

  "bar.classPath" -> "qux.compile" [constraint=false];
  "bar.classPath" -> "qux.classPath"
  "qux.mainClass" -> "qux.assembly"
  "qux.sources" -> "qux.compile" -> "qux.classPath" -> "qux.assembly"
}
....

Apart from the various tasks doing different things, we also see multiple modules
with similar task layouts (`foo`, `bar` and `qux`), but with subtle customizations in
each module to wire them up
(e.g. `foo.classPath` having one upstream task but `bar.classPath` and `qux.classPath`
each having two). And this is one of the simplest possible builds: you can imagine that
with compiler and runtime flags, code-generation, dependency-downloading, different language
toolchains, these graphs can get complicated quickly. And any build tool will need some way
for the user to define these graphs and maintain them over time.

Most build tools provide ad-hoc config formats (Maven's XML) or programmable builder
APIs (e.g. Gradle's Groovy/Kotlin) to satisfy this need, but these ad-hoc formats
inevitably end up being unfamiliar and confusing to users (e.g. the Gradle code
xref:#_mill_vs_gradle_configuration_as_code[discussed above]). Many
tools try to hide complexity behind plugins, but that doesn't actually solve it: plugin
authors are human too, and can also make mistakes and cause bugs when publishing their plugins.
It doesn't matter whether the bugs are in your own build customization or in the plugins
you use if the end result is your build system becomes slow and flaky!


Fundamentally, defining an API for templated, customizable graph-computations is
non-trivial, so it is not surprising the APIs and to do so can get complicated. But Mill
has one big insight in how it can be done better:

=== Object-Oriented Build Pipelines

Mill has the same requirement of defining templated, customizable graph-computations, but
rather than inventing a bespoke programming, configuration and plugin model to do so, Mill
builds upon what everyone already knows: _Object-Oriented Programming_. It turns out that the
object-oriented programming every Java developer learned in school provides all the key
building blocks necessary to define templated, customizable graph-computations:

- *Methods* provide a way of defining discrete build steps that perform
some necessary action in your build

- The *Call Graph* between methods provides the build graph, where which method call
which other methods defines the incoming edges of that node in the graph

- *Classes* provide the templating, where you can define a set of methods calling each
other, and instantiate those call graphs more than once in different parts of your build

- *Overrides* and *Subclasses* provide customization: when a particular instance or
sub-class needs a different implementation of one-or-more build steps, you can
override the respective methods to customize the build call graph to your liking

Thus, when you see a Mill build configured as such, with an `object` extending a `class`:

[source,scala]
----
package build
import mill.*, javalib.*

object foo extends JavaModule {
}
----

This is not some special syntax, but is literally defining an object named `foo`
inheriting from the class `JavaModule`. Like any other inheritance, this picks up
the methods and method call graph of `JavaModule` (slightly simplified below)

[graphviz]
....
digraph G {
  rankdir=LR
  node [shape=box width=0 height=0 style=filled fillcolor=white]
  bgcolor=transparent
  newrank=true;
  subgraph cluster_0 {
    style=dashed
    node [shape=box width=0 height=0 style=filled fillcolor=white]
    label = "foo";

    "foo.sources" -> "foo.compile" -> "foo.classPath" -> "foo.assembly"
    "foo.resources" -> "foo.assembly"
  }
}
....

And when you add additional tasks by defining methods using `def`, or `override` tasks
and call `super`:

[source,scala]
----
package build
import mill.*, javalib.*

object foo extends JavaModule {
  /** Total number of lines in module source files */
  def lineCount = Task {
    allSourceFiles().map(f => os.read.lines(f.path).size).sum
  }

  /** Generate resources using lineCount of sources */
  override def resources = Task {
    os.write(Task.dest / "line-count.txt", "" + lineCount())
    super.resources() ++ Seq(PathRef(Task.dest))
  }
}
----

You as a Java programmer already know how these changes affect the build graph, by splicing
in the new method `foo.lineCount`, replacing `foo.resources` with a new method body, and
calling `foo.super.resources`:

[graphviz]
....
digraph G {
  rankdir=LR
  node [shape=box width=0 height=0 style=filled fillcolor=white]
  bgcolor=transparent
  newrank=true;
  subgraph cluster_0 {
    style=dashed
    node [shape=box width=0 height=0 style=filled fillcolor=white]
    label = "foo";

    "foo.sources" -> "foo.compile" -> "foo.classPath" -> "foo.assembly"
    "foo.super.resources" -> "foo.resources" -> "foo.assembly"  [color = darkgreen, penwidth=3]
    "foo.lineCount"  [color = darkgreen, penwidth=3]
    "foo.sources" -> "foo.lineCount" -> "foo.resources" [color = darkgreen, penwidth=3]
    "foo.resources" [color = darkgreen, penwidth=3]
  }
}
....

If you want to re-use your build pipeline customizations, it as simple as turning the
`object foo` into a `class MyJavaModule` (called a `trait MyJavaModule` in Mill's syntax), so it
can be inherited  by `object foo` and `object bar` to share the configuration:


[source,scala]
----
package build
import mill.*, javalib.*

object foo extends MyJavaModule
object bar extends MyJavaModule

trait MyJavaModule extends JavaModule {
  /** Total number of lines in module source files */
  def lineCount = Task {
    allSourceFiles().map(f => os.read.lines(f.path).size).sum
  }

  /** Generate resources using lineCount of sources */
  override def resources = Task {
    os.write(Task.dest / "line-count.txt", "" + lineCount())
    super.resources() ++ Seq(PathRef(Task.dest))
  }
}
----

[graphviz]
....
digraph G {
  rankdir=LR
  node [shape=box width=0 height=0 style=filled fillcolor=white]
  bgcolor=transparent
  newrank=true;
  subgraph cluster_1 {
    style=dashed
    node [shape=box width=0 height=0 style=filled fillcolor=white]
    color = darkgreen
    penwidth=3
    label = "bar";

    "bar.sources" -> "bar.compile" -> "bar.classPath" -> "bar.assembly"
    "bar.super.resources" -> "bar.resources" -> "bar.assembly"
    "bar.lineCount"
    "bar.sources" -> "bar.lineCount" -> "bar.resources"
    "bar.resources"
  }
  subgraph cluster_0 {
    style=dashed
    node [shape=box width=0 height=0 style=filled fillcolor=white]
    label = "foo";

    "foo.sources" -> "foo.compile" -> "foo.classPath" -> "foo.assembly"
    "foo.super.resources" -> "foo.resources" -> "foo.assembly"
    "foo.lineCount"
    "foo.sources" -> "foo.lineCount" -> "foo.resources"
    "foo.resources"
  }

}
....

If you want to further customize either of those modules, you can `override`
one or more of the inherited methods. And if you want to publish your customizations
for others to use in their own projects,
you can xref:extending/writing-plugins.adoc#_publishing[publish
MyJavaModule to Maven Central] for others to
xref:extending/import-mvn-plugins.adoc[import into their build].

Mill's usage of methods, classes, and overrides is also what powers the IDE support
discussed earlier on this page. IDEs like IntelliJ or VSCode are uniquely adept at
working with JVM codebases full of methods and classes, and so
they can help you navigate and understand your Mill build pipelines just as easily
as any application codebase. And the simplicity of this extension model is what
allows Mill developers to avoid making mistakes aroun caching or parallelism when setting
up their builds or publishing plugins, which ultimately is what gives Mill builds great
performance without ever needing to `clean`.

== Conclusion

Although superficially Mill's programmable `build.mill` syntax looks similar to Gradle's
`build.gradle` or `build.gradle.kts`, under the hood it works very differently. Where
Gradle works via a custom DSL that gets and sets global mutable variables that both humans
and IDEs have trouble analyzing, Mill works by defining classes, subclasses, methods and overrides:
all of which are bog-standard concepts from object-oriented programming that both humans and
IDES have had decades of experience with.

Thus Mill's programmable build definitions end up being much easier to learn and much
easier to navigate in your editor than Gradle's, or those of other build tools like SBT
or Bazel. This gives you the benefit of programmable builds without the complexity and
confusion that has often accompanied such tools in the past.

