=== WordCount (batch)

Goal: read a small text, tokenise, count top words.

[source,scala]
----
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions.col

object Main extends App {
  val spark = SparkSession.builder().appName("WordCount").master("local[*]").getOrCreate()
  import spark.implicits._

  val lines  = Seq("hello mill spark", "hello spark").toDS
  val words  = lines.flatMap(_.split("\\s+"))
  val counts = words.groupByKey(identity).count().toDF("word","count").orderBy(col("word").asc)

  counts.show(false)
  spark.stop()
}
----

Run:

[source,bash]
----
mill sparkdemo.run
----

.Expected output (example)
[%collapsible]
====
[source,text]
----
+------+-----+
|word  |count|
+------+-----+
|hello |2    |
|mill  |1    |
|spark |2    |
+------+-----+
----
====

Pitfalls: Ensure local mode (`master("local[*]")`) for quick runs; large inputs need `.repartition`.